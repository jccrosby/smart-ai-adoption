---
# You can also start simply with 'default'
theme: ./theme
# some information about your slides (markdown enabled)
title: AI for Teams - Smart Adoption Not Blind FOMO
info: |
    AI won’t take your job—but someone using it smarter will. Don’t fall for the hype or the FOMO. This talk gives you the tools to evaluate AI, adopt it wisely, and build a practical rubric for making smart AI decisions—for you, your career, and your team.
author: John Crosby
# apply unocss classes to the current slide
class: text-center
# https://sli.dev/features/drawing
drawings:
    persist: false
fonts:
    sans: Lora
    serif: Roboto Slab
    mono: Fira Code
# slide transition: https://sli.dev/guide/animations.html#slide-transitions
transition: slide-left
exportFilename: smart-ai-adoption
# enable MDC Syntax: https://sli.dev/features/mdc
mdc: false
colorSchema: auto
---

# AI for Teams - Smart Adoption Not Blind FOMO

<!--
AI for Teams - Smart Adoption Not Blind FOMO

Welcome!
-->

---
layout: intro
introImage: /images/john-crosby.jpg
email: john@hellocrosby.com
bsky: jccrosby.com
---

# John Crosby

## Principal Engineer, Client Engineering @ MLB

<!--
Background

- In a previous life I was a Professional Chef.
- I moved from restaurants to project managing for a 3D animation and web development company.
- That's where I caught the programming bug.
- Then started a web development and training consultancy and ran that for just over a decade.
- Then I joined MLB and have been working in the MLB.tv and streaming space.
- I'm working on my 11th season at MLB.

All that is to say, because of my non-traditional background and experience I'm uniquely positions to observe, understand, and navigate changes like those we're seeing with the advancements in AI.
-->

---
layout: new-section
sectionImage: /images/smart-vs-fomo-chatgpt.png
imageWidth: 512
imageHeight: 341
---

# Navigating AI for Teams

## Smart Adoption vs. Blind FOMO

<!--
Navigating AI for Teams

Smart Adoption vs. Blind FOMO

1. What I see right now is a lot of fear mongering out there
   1. AI is going to take all our jobs!
   2. AI won’t take your job—but someone using it smarter will.
2. The pressure is real.
3. But AI is a tool, not a magic wand.
4. Just like any other tool, the key is to understand it and adopt it wisely, not blindly.

That's my hope for this talk - to provide a simple, flexible way navigate changes, avoid pitfalls, and make better informed decisions for your organization and teams.
-->

---
layout: image
image: /images/ai-landscape.png
---

<div class="bg-[#fff]/70 p-10 rounded-lg text-red-500 text-7xl text-align-center">The Current Landscape</div>

<!--
The Current Landscape

1. Questions
   1. Who here
      1. ...leads a team or group of teams?
   2. How many of you have said or heard some form of "we need to do something with AI"?
2. Because that and the sheer volume of AI advancements, the news around it, and new tools showing up almost every day.
3. There is a lot of overwhelm from from the hype
4. The truth is regardless of the number of teams you're part of or leading, we're all going to have to deal with these changes.
-->

---
layout: center
---

# The Dual Edge: Hype vs. Opportunity

## The pressure to "do something with AI" can lead to rushed decisions & poor outcomes

<!--
The Dual Edge: Hype vs. Opportunity

The pressure to "do something with AI" can lead to rushed decisions & poor outcomes

1. It's an exciting time though! AI offers opportunities like
   1. Enhanced productivity
   2. Better quality
   3. Faster cycles or higher velocity
   4. More innovation more often
2. There are risks that come along with that - FOMO is a big driver of that
   1. You want to jump on the opportunities, but there's no direction - lack of clear goals
   2. There's not a plan
   3. and there is no coherent strategy
   4. "just get out there and make sure we're using it"

The challenge is to navigate this quickly evolving landscape smartly, so we can harness those opportunities and avoid the risks and pitfalls.
-->

---
layout: center
---

# Smart Adoption vs. Blind FOMO

## The Core Difference

<!--
What does Smart adoption look like vs. Blind FOMO?

1. Blind FOMO
   1. Is very reactive
   2. Skips learning and planning
   3. Technology-centric
   4. Driven by hype or fear rather than a specific problem
   5. Doesn't allow for measurement and the ability to critically assess efforts and their results
2. Smart Adoption on the other hand
   1. Is proactive
   2. It involves learning and planning before any significant investment
   3. Which means
      1. Being deliberate
      2. Being strategic
      3. Focusing on identifying and solving specific problems
      4. Creating measurable results so you know when you've succeeded (and when you haven't)
      5. Then assessing those results

Which leads me to my first tenet...
-->

---
layout: statement
---

<div class="text-center text-7xl text-red-500 font-bold">The implementation of AI matters more than its mere adoption.</div>

<!--
**The implementation of AI matters more than its mere adoption.**

- It might be difficult to be more proactive and strategic, but in the end you're going to save time & effort and gain a better understanding of where AI should fit in your organization.
-->

---
layout: new-section
sectionImage: /images/core-principles.jpeg
---

# Core Principles of Effective AI Adoption

## Foundational Principals to Smart Adoption

<!--
Core Principles of Effective AI Adoption

Foundational Principals to Smart Adoption

- To frame that proactive and strategic approach, I'd like to share six principles.
-->

---
layout: default
---

# Six Core Principles

1. **Strategic Alignment:** Define _why_ before _what_.
2. **Data Readiness & Governance:** Poor data leads to failure.
3. **Skills & Culture:** Learning, experimentation, critical assessment, and sharing are key.
4. **Technology & Infrastructure:** The right tools in the right place.
5. **Ethics & Responsibility:** Fairness, transparency, privacy, security
6. **Iterative Approach:** Short feedback loops and continuous learning.

<!--
Six Core Principles

1. Strategic Alignment: where you look to solve specific problems aligned with your business goals.
   1. You need to know the _why_ before _what_.
2. Data Readiness & Governance: You need to ensure data quality, accessibility, security, and governance because poor data leads to failure.
   1. Basically, garbage in equals garbage out.
3. Skills & Culture: AI adoption is going to require technical skills and a supportive culture.
   1. That supportIve culture encourages experimentation, learning, and sharing.
   2. Which can be difficult to foster if it doesn't already exists, but it's worth the effort.
4. Technology & Infrastructure: You're going to need to select the right tools that are compatible with existing workflows and processes.
5. Ethics & Responsibility: Those considerations need to be in place form the beginning - Fairness, transparency, privacy, security
   1. And you need to be willing to update and adjust when and where it makes sense in a way that makes sense
6. An Iterative Approach: You know you're solving specific problems
   1. Based on those problems start with small experiments
   2. Then you can execute and learn from those experiments
   3. Because you're looking for short feedback cycles so you can learn and adjust appropriately

Keeping these principles in mind is going ot help focus the efforts and help to make better informed decisions.
-->

---
layout: new-section
sectionImage: /images/LEAP-cycle.png
---

# The L.E.A.P. Framework

## An Iterative Process for Smart Adoption

<!--
Which leads hme to the L.E.A.P. Framework

1. The six core principles, are encompassed in "four-ish" steps
2. These steps
   1. Focus on maximizing value while mitigating risks.
   2. Encourage iterative progress and critical evaluation.
   3. Emphasize measurement and learning from both _successes_ AND _failures_.

LEAP provides a sustainable and flexible process that can
   - Be applied to any level of an organization
   - and be adapted to fit specific needs

In short, it's a structured, repeatable way to help navigate AI adoption.

Let's take a look at the steps.
-->

---
layout: two-cols-header
---

# 1. LEARN

## Understand AI capabilities and limitations

::left::

# Activities

- Research AI tools and advancements.
- Identify pain points in your process.
- Assess team skills.
- Evaluate data availability and quality.
- Consider ethical and security implications.
- Define **SMART** goals for experiments.

::right::

# Output

- Prioritized use cases.
- Readiness assessment.
- Defined success metrics.

<!--
- Step Number 1 - Learn: You're gaining a solid understanding of your goals and the AI tools can help to achieve those goals.
- This step is where you're
  - Understanding the your specific landscape
  - and creating your plan

That means you're going to:

 1. Identify the bottlenecks, pain points, and problems in your process or workflows.
 2. Research AI tools and advancements that could be used to solve those problems.
 3. Looks at your team and assess their skills
 4. Evaluate the data you have and data you think you need
 5. Consider ethical and security implications
 6. And finally you need ot define goals for experiment - those goals should be "SMART"
    1. Specific, Measurable, Achievable, Relevant, Time-bound

So the output of all this work is:

1. Prioritized list of use cases
2. Assessment of your readiness
3. And defined metrics for success
-->

---
layout: two-cols-header
---

# 2. EXPERIMENT

## Focus on small-scale, controlled pilots.

::left::

# Activities

- Select a low-risk project experiments.
- Choose specific AI tool/model.
- Develop and execute a prototype or limited integration.
- Gather quantitative and qualitative feedback.

::right::

# Output

- Working prototype.
- Performance data.
- User feedback.
- Lessons learned.

<!--
- Step Number 2 - Time to experiment
- This is where you put your plan into action and
- Focus on those small-scale, controlled experiments to test your assumptions and hypothesis

Now you're going to::

1. Select a one of those experiments
2. Choose the AI tool, model etc. that you've identified that will help you solve that problem
3. Develop and execute your experiment
4. Gather quantitative and qualitative feedback

So the output for the Experiment step is:

1. Working prototype
2. Performance data and metrics
3. User feedback in the form of surveys and/or interviews
4. And possibly some lessons learned
-->

---
layout: two-cols-header
---

# 3. ASSESS

## Critically evaluate outcomes to make better decisions.

::left::

# Activities

- Evaluate results against your goals.
- Analyze the benefits vs. costs
- Assess impact on workflow, quality, productivity, satisfaction.
- Identify challenges and risks.
- Review ethical and security concerns.
- Make a clear **Go/No-Go** decision.

::right::

# Output

- A more refined understanding of requirements and the results.
- An assessment report.
- A clear decision.

<!--
- Now that you're done with the experiment, it's time to assess.
- Step Number 3 - is where you get to
  - take a step back and
  - evaluate the results and outcomes and make some decisions.

When assessing the results you're:

1. Looking at those results relative your goals
2. Your analyzing benefits vs. costs (ROI)
3. Assessing the impact on the things that matter - workflow, quality, productivity, satisfaction, etc.
4. Validating the output
5. Reviewing for ethical and security concerns
6. Identifying challenges and risks that may have popped up
7. Then finally based on all of that you're going to make a clear **Go/No-Go** decision

All of this should lead to

1. A better understanding of requirements and the results.
2. Some useful data and reports
3. A clear decision of that experiment

- It boils down to this - you're assessing if AI is adding value and if it is worth scaling or not.
- Which then means you have a decision to make...
-->

---
layout: default
---

<h1 class="absolute left-4 pl-30">PIVOT</h1>
<h1 class="absolute right-6 pr-30">PROPAGATE</h1>

<!--
- That decision is the "P" in LEAP
  - Pivot
  - Propagate
  - and why I said it's "four-ish" steps.
-->

---
layout: two-cols-header
---

# 4. PIVOT

## If the experiment fails or needs adjustment

::left::

# Activities

- Analyze failure points and gather feedback.
- Adjust goals, tools, or methods based on insights.
- Reassess readiness and risks.
- Iterate on the experiment with a new focus or move to another experiment.

::right::

# Output

- Revised experiment plan.
- Updated goals.
- A new approach to testing.

<!--
Step 4 - PIVOT

- If you're going to pivot, that means the experiment didn't work out how you expected, or it was an outright failure
- It's not bad thing to fail, it's expected and useful because you get to learn from and inform next steps.

Those next steps are:

1. Analyze failure so you can
2. Adjust goals, assumptions, tools, or methods based on any insights you've gained.
3. Reassess readiness and risks.
4. Then iterate - that could mean
   1. Adjustments to the experiment or
   2. A brand new experiment

Output:

1. Revised or new experiment plan based on what you've learned.
2. And possibly updated goals.

...if you're not Pivoting, you're Propagating...
-->

---
layout: two-cols-header
---

# PROPAGATE

## Strategically scale successful AI applications.

::left::

# Activities

- Develop a detailed rollout roadmap.
- Identify infrastructure and tooling changes.
- Create and execute training programs.
- Establish governance policies and monitoring.

::right::

# Output

- A useable AI solution.
- Maintenance & governance structures.
- Ongoing monitoring plan.
- Up-skilled team.

<!--
- Step Number 4 - Propagate: Which means you're rolling out the solution because it was a success!

This means:

1. You're going to need a roadmap to rollout the successful experiment. That roadmap should include:
   1. Any changes you need to make to infrastructure and tooling
   2. Training programs to up-skill your teams(s)
   3. Updated or new governance policies and monitoring processes

So you'll end up with:

1. That useable AI solution
2. A process for maintaining and governing that solution
3. A plan for monitoring and maintaining it
4. An up-skilled team/organization

- The goal is to make sure the AI solution you're putting in place is sustainable and effective.

Now, regardless of a Pivot or Propagate, there's something else that needs happen.
-->

---
layout: center
---

<div class="text-red-500 text-6xl">Share what you've learned from the successes and failures.</div>

<!--
Tenet Number 2 - Share
- Sharing is an essential part of expanding the benefits of any effort like this.
- Also, it doesn't need to happen just at the end
- I think it can and should happen at any stage of the process.
-->

---
layout: new-section
sectionImage: /images/exec-fomo.png
---

# Story time:

# Blind FOMO

## Cursor: AI Tooling For Coding

<!--
Analogy - Blind FOMO

Cursor: AI Tooling For Coding

1. Alright, story time.
2. This is a little contrived but I did that to protect the innocent - but it does have it's roots in reality.
3. Our group received messaging something alone the lines of "Use Cursor to be more productive! We want to see it increase teams velocity."
1. Cursor, if your not familiar, is a gen AI tool for code - "The AI Code Editor - Built to make you extraordinarily productive, Cursor is the best way to code with AI." is their tag line.
2. The team was told basically, to "check it out".
3. There was no clear goal or understanding of what anyone was really supposed to do or how.
4. Additionally
   1. The InfoSec team hadn't evaluated or approved it.
   2. Legal hadn't looked at it or approved it.
   3. There was no training or onboarding.
   4. There wasn't a budget for it. It was a "use the free trial and see what happens" situation.
5. This might have also been presented on March 5th.
   1. Spring Training started on February 20th
   2. Opening Day was March 27th.
   3. So right in the middle of one of the busiest times of the year for everyone involved.
6.  For sake of this example let's say this was presented to 30 engineers across multiple teams and different concerns.
7.  That means this ended up being 30 isolated "experiments" going on at once with
    1.  No clear goals
    2.  No way to know what should be measured or how to measure it
    3.  No timeline to deliver results
8.  It basically turned into a subjective and unbounded "some like it, some don't"

Not very effective, not very efficient.
-->

---
layout: default
---

# The Cursor "Experiment"

- **Skipped Learn:** Vague goal, focused on tech over specific problems, and ignored readiness
- **Skipped Experiment/Assess:** We had no clear goals, no way to measure success, and no understanding of the risks
- **Failed Pivot/Propagate:** Resulted in chaos, inconsistent usage, wasted resources and time, potential security and IP issues, no way to measure impact

<!--
So, that experiment was a failure, but not because of the tool. Because of the process or really, lack of process.

If we look at it from the perspective of LEAP:

- **Skipped Learn:**
  - Vague goal ("increase velocity")
  - Focused on tech (GenAI) over specific problems
  - Ignored readiness (knowledge, skills, codebase, IP)
- **We weren't able to Experiment or Assess because:**
  - We had no clear goals
  - We didn't have any metrics to measure success
  - and there was zero understanding of the risks
- **Pivot or Propagate is out the window because:**
  - The "experiment" if you can call it that resulted in chaos
  - There was no consistency in experimentation and usage
  - No understating of potential security and intellectual property (IP) risks
  - No way to measure impact

So, all we really did was end up wasting resources and time
-->

---
layout: new-section
sectionImage: /images/five-questions-chatgpt.png
---

# Smart AI Adoption: How to Evaluate AI for Your Team

## Five Questions to Ask

<!--
- LEAP is used to avoid this kind of situation
- An important part of LEAP is to define your goals and research and evaluate AI tools to help achieve those goals.
- The following are five questions that I've identified that should help with this.
-->

---
layout: new-section
sectionImage: /images/Q1-Solve-real-problems-gemini.jpeg
---

# Question 1:

# Does it solve a **real problem**, or is it just "cool"?

<!--
Question 1 - Does it solve a **real problem**, or is it just "cool"?

- **LEAP - Learn:**
  - In the Learn step, you're identify your goals and potential AI solutions.
  - This question makes sure the AI solution is appropriate for your goals.
- **Red Flag:**
  - Vague use cases
  - No clear tangible problems

The Cursor "experiment" is a great example of this.
- Cursor could be a great tool, but the goal of "increase velocity" was too vague
- And everyone was focused on the tool rather than the problem
-->

---
layout: new-section
sectionImage: /images/Q2-Efficiency-quality-matrix-chatgpt.png
---

# Question 2:

# How does it impact **efficiency vs. quality**?

<!--
Question 2 - How does it impact **efficiency vs. quality**?

The matrix illustrates trade-offs you should keep in mind

- **LEAP - Assess:**
  - You should be evaluating the impact of your experiments on workflows & processes as it relates to BOTH efficiency and quality.
- **Red Flag:**
  - Overemphasis on one or the other could hide potential issues.

- The Cursor "Experiment" only focused on the vague goal of "increase velocity"

- This also reminds me of "Vibe coding", in that you're trusting the output without regard to its quality
  - If you're not familiar with what vibe coding is or have a strong opinion, I'd love to talk about it later
-->

---
layout: new-section
sectionImage: /images/Q3-Risks.png
---

# Question 3:

# What are the **risks**?

<!--
Question 3 - What are the **risks**?

- **LEAP - Learn & Assess:**
  - Here you're proactively considering any bias, security, or ethical risks
- **Red Flags:**
  - Unverified or biased data
  - Weak security
  - Lack of guidelines around ethics, security, or intellectual property (IP)

- The Cursor "Experiment" didn't consider any of these risks
-->

---
layout: new-section
sectionImage: /images/Q4-Verification.jpeg
---

# Question 4:

# Can we **trust the outputs**?

<!--
Question 4 - Can we **trust the outputs**?

- **LEAP - Experiment & Assess:**
  - This is where you gather data and feedback on the reliability of the outputs.
  - and you assess them for accuracy and validity
- **Red Flags:**
  - Limited testing
  - Black-box models
  - No defined process for verification

- I'm sure you can see how the Cursor "Experiment" failed here too.
- This is another great example of issues with "Vibe coding".
-->

---
layout: new-section
sectionImage: /images/Q5-Workflows.png
---

# Question 5:

# How does it fit with our **existing workflows**?

<!--
Question 5 - How does it fit with out **existing workflows**?

- **Learn & Propagate:**
  - Identify how the AI solution integrates with existing processes.
  - to ensure compatibility and minimize disruption.
- **Red Flags:**
  - Inadequate training
  - Lack understanding of IT/operational readiness
  - Major workflow disruptions
-->

---
layout: image-right
image: /images/red-flags-gemini.jpeg
---

## Red Flags to Watch For

- Hype-driven adoption
- Vague use cases
- Overemphasis on speed alone
- No clear KPIs
- Hidden quality costs
- Unverified data sources
- Weak security and privacy protocols
- No ethical guidelines
- Black-box models with no explanation
- Inadequate user training
- Lack of operational readiness
- No mechanism for verification
- Limited testing
- Major workflow disruption

<!--
In general, there are some red flags to watch for when evaluating AI:

You want to make sure:
- You can measure what you need to
- Ethical guidelines are being followed
- There aren't major workflow disruptions
- Security and privacy is being accounted for
- etc...

Red Flags to Watch For

- Hype-driven adoption
- Vague use cases
- Overemphasis on speed alone
- No clear KPIs
- Hidden quality costs
- Unverified data sources
- Weak security protocols
- No ethical guidelines
- Black-box models with no explanation
- Inadequate user training
- Lack of operational readiness
- No mechanism for verification
- Limited testing
- Major workflow disruption
-->

---
layout: new-section
sectionImage: /images/Practical-AI-Use-Cases.png
---

# Practical AI Use Cases

## Leveraging AI Across Concerns

<!--
- To help illustrate LEAP, I've created a an example experiments for each of
- the following use cases across different concerns.
-->

---
layout: default
---

# AI in Requirements Engineering

- NLP/LLMs for eliciting, analyzing, and validating requirements.
- Generating user stories and initial system models.
- **LEAP:**
    - **Learn:** Analyze requirements for ambiguity using NLP.
    - **Experiment:** Analyze a few existing user stories.
    - **Assess:** Gather feedback on improved clarity.
    - **Propagate:** Scale use the NLP tools.

<!--
AI in Requirements Engineering

- Natural language processing and LLMs to generate, analyze, and validate requirements.
- This can be as simple as generating user stories or using AI to generate full-blown system models.
- **LEAP:**
  - **Learn:** We've identified that we'd like to analyze requirements for ambiguity using NLP.
  - **Experiment:** Use NLP to analyze a small set of user stories.
  - **Assess:** Gather feedback on improved clarity.
  - **Propagate:** Scale use of validated NLP tools. Distribute the tools to whoever needs them for this process.
    - We'll also want to consider training and onboarding etc.
-->

---
layout: default
---

# AI-Assisted Code

- Tools like GitHub Copilot, Cursor, Gemini Code Assist, Amazon Q, and Claude Code.
- Capabilities: code generation, explanation, refactoring suggestions, bug fixes and identification.
- **LEAP:**
    - **Learn:** Research tools, their security implication, and best practices.
    - **Experiment:** Pilot with a small team on specific contained task.
    - **Assess:** Evaluate code quality and developer productivity.
    - **Propagate:** Roll out with guidelines, training, and best practices.

<!--
- Tools like GitHub Copilot, Cursor, Gemini Code Assist, Amazon Q, and Claude Code.
- Capabilities: code generation, explanation, refactoring suggestions, bug fixes and identification.
- **LEAP:**
  - **Learn:** Research tools and their security implications.
  - **Experiment:** Pilot with a small team on specific tasks.
  - **Assess:** Evaluate code quality and developer productivity.
  - **Propagate:** Roll out with training and best practices.
-->

---
layout: default
---

# AI-Driven QA

- LLMs and specialized models for generating unit, integration, and end-to-end tests.
- AI for GUI testing, fuzz testing, visual regression, bug detection, chaos testing.
- **LEAP:**
    - **Learn:** Identify repetitive testing tasks.
    - **Experiment:** Use AI to generate tests for non-critical components.
    - **Assess:** Measure code coverage and effort required.
    - **Propagate:** Integrate successful techniques into QA workflows.

<!--
AI-Driven QA

- LLMs and specialized models for generating unit, integration, and end-to-end tests.
- AI for GUI testing, fuzz testing, visual regression, bug detection.
- **LEAP:**
  - **Learn:** Identify repetitive testing tasks.
  - **Experiment:** Use AI to generate tests for non-critical components.
  - **Assess:** Measure code coverage and effort required.
  - **Propagate:** Integrate successful techniques into QA workflows.
-->

---
layout: default
---

# AI in DevOps

- Automation of CI/CD, intelligent monitoring, anomaly detection, predictive failure analysis.
- **LEAP:**
    - **Learn:** Identify manual DevOps bottlenecks.
    - **Experiment:** Automate a deployment or set of deployments.
    - **Assess:** Measure impact on deployment time and reliability.
    - **Propagate:** Expand automation across more services.

<!--
AI in DevOps

- Automation of CI/CD pipelines, intelligent monitoring, anomaly detection, predictive failure analysis.
- **LEAP:**
  - **Learn:** Identify manual DevOps bottlenecks.
  - **Experiment:** Automate a deployment or set of deployments.
  - **Assess:** Measure impact on deployment time and reliability.
  - **Propagate:** Expand automation across more services.
-->

---
layout: default
---

# AI-Assisted Project Management and Reporting

- AI for task prioritization, resource allocation, and risk management.
- Automated reporting and status updates.
- **LEAP:**
    - **Learn:** Identify repetitive reporting tasks.
    - **Experiment:** Use AI to generate reports for a small project.
    - **Assess:** Measure time saved and accuracy.
    - **Propagate:** Integrate successful techniques into PM workflows.

<!--
AI-Assisted Project Management and Reporting

- AI for task prioritization, resource allocation, and risk management.
- Automated reporting and status updates.
- **LEAP:**
  - **Learn:** Identify repetitive reporting tasks.
  - **Experiment:** Use AI to generate reports for a small project.
  - **Assess:** Measure time saved and accuracy.
  - **Propagate:** Integrate successful techniques into PM workflows.
-->

---
layout: default
---

# AI for Security Analysis

- Enhanced threat detection, log analysis, vulnerability assessment, automated Security Operations Center (SOC) tasks.
- AI tools for code vulnerability scanning.
- **LEAP:**
    - **Learn:** Research AI-powered security tools.
    - **Experiment:** Run Static Application Security Testing (SAST) tools on a feature branch.
    - **Assess:** Analyze false positive/negative rates.
    - **Propagate:** Integrate validated tools into the DevSecOps pipeline.

<!--
AI for Security Analysis

- Enhanced threat detection, log analysis, vulnerability assessment, automated Security Operations Center (SOC) tasks.
- AI tools for code vulnerability scanning.
- **LEAP:**
  - **Learn:** Research AI-powered security tools.
  - **Experiment:** Run Static Application Security Testing (SAST) tools on a feature branch.
  - **Assess:** Analyze false positive/negative rates.
  - **Propagate:** Integrate validated tools into the DevSecOps pipeline.
-->

---
layout: center
---

# Communicating AI Strategy to Leadership

## Emphasize Value and the Risk Management

<!--
Communicating AI Strategy to Leadership

Emphasize Value, Risk Management, and the LEAP Framework

- Using a framework like LEAP to demonstrate a structured approach to AI adoption allows you to
  - Highlight the importance of risk management and ethical considerations.
  - Focus on the value AI can bring to the organization.
  - Emphasize the iterative nature of the process and the value of learning from both successes and failures.
-->

---
layout: center
---

# Conclusion & Takeaways

## Embrace AI Thoughtfully and Strategically

<!--
Conclusion & Key Takeaways

Embrace AI Thoughtfully and Strategically

- Integrating AI into and organization or team requires careful consideration and planning.
- The LEAP framework provides a structured approach for AI adoption.
  - It's a simple, practical, repeatable process
  - **Learn** before acting.
  - **Experiment** in a controlled manner.
  - **Assess** results critically.
  - **Pivot** when necessary or **Propagate** those successful initiatives sustainably.
-->

---
layout: center
---

# Call to Action

## Move beyond passive observation of AI.

<!--
Call to Action

- I want you to **Start a LEAP cycle ->** by identify a pressing challenge.
- Find potential AI solution.
- Define a clear goal for a small experiment.
- Embrace the learning process and iterate.
- This will help to chart a course for smart AI adoption that delivers real value.

**And Again, SHARE your successes and failures! that's who you expand the **
-->

---
layout: end
bsky: jccrosby.com
email: john@hellocrosby.com
github: https://github.com/jcrosby/smart-ai-adoption
---

<div class="text-8xl font-bold">Thank You!</div>

<!--
**Thank you!**

_**Does anyone have any questions?**_

I appreciate everyone's time and attention today.

Enjoy the rest of the the conference.
-->
